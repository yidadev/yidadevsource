
关于Lock的问题：

各种锁的性能对比： 性能从最优到最差：osspinLock -> dispatch_semaphore -> pthread_mutex -> NSLock -> NSCondition -> pthread_metex(recursive) -> NSRecursiveLock -> NSConditionLock -> @synchronized.

依次从性能最优到性能最差:

### 自旋锁
关于OSSpinLock，关于自旋锁的问题：

开发者保证访问锁的线程全部都处于同一优先级，否则 iOS 系统中所有类型的自旋锁都不能再使用了。

为什么说 OSSpinLock是不安全的，新版iOS中维护了5个不同线程优先级， background , utility , default , user-initiated , user-interactive，高优先级始终会在低优先级前执行，一个线程不会受到比他更低优先级线程的干扰，这种线程调度算法会产生潜在的优先级反转问题，，从而破坏了spin lock。
具体来说，如果一个低优先级的线程获得锁并访问共享资源，这时一个高优先级的线程也尝试获得这个锁，它会处于spin lock的忙等待从而占用大量的CPU，此时低优先级线程与高优先级线程争夺CPU时间，从而导致任务迟迟完不成，无法释放lock。

解决方案： 使用hand off lock 算法， 锁的持有者会把线程ID保存到锁的内部，锁的等待者会临时贡献出它的优先级来避免优先级翻转的问题，理论上这种模式会比较复杂的多锁条件下产生问题，但实践上目前还一切都好。

``` xml
自己实现这一套，目前没有发现有异常，即便创建的队列处于不同等级，暂时没出现自选锁引发的问题。

   dispatch_queue_t queue2 = dispatch_get_global_queue(QOS_CLASS_UTILITY, 0);
    //低优先级队列
    dispatch_queue_t queue3 = dispatch_get_global_queue(QOS_CLASS_BACKGROUND, 0);
    //init的初始化的信息
    __block OSSpinLock pinLock = OS_SPINLOCK_INIT;
    dispatch_async(queue2, ^{
        NSLog(@"线程2 准备上锁");
        OSSpinLockLock(&pinLock);
        sleep(4);
        NSLog(@"线程2");
        OSSpinLockUnlock(&pinLock);
        NSLog(@"线程2 解锁成功 --------");
    });
    dispatch_async(queue3, ^{
        NSLog(@"线程3 准备上锁");
        OSSpinLockLock(&pinLock);
        sleep(4);
        NSLog(@"线程3");
        OSSpinLockUnlock(&pinLock);
        NSLog(@"线程3 解锁成功 ---------");
    });
```

### 信号量：
dispatch_semaphore_t GCD中信号量，也可以解决资源抢占问题,支持信号通知和信号等待。每当发送一个信号通知，则信号量+1；每当发送一个等待信号时信号量-1,如果信号量为0则信号会处于等待状态，直到信号量大于0开始执行.

``` xml
创建信号量: 创建一个信号量为1的信号。
dispatch_semaphore_t semaphore = dispatch_semaphore_create(1);
//DISPATCH_TIME_FOREVER等待时间，wait之后信号量-1，为0
dispatch_semaphore_wait(semaphore, DISPATCH_TIME_FOREVER);
发送一个信号量，这时候信号量是1。
//发送一个信号量，这时候信号量+1，为1
dispatch_semaphore_signal(semaphore);
```

可以通过信号量的方式，创建信号量，设置初始值是1，每次发请求前做下wait，知道请求数据回来，做一次signal，然后再次做第一个请求的发送，这样可以实现一个串行的数据队列。

关于信号量的使用，产生的互斥锁
``` xml
dispatch_semaphore_t semaphore  = dispatch_semaphore_create(1);
dispatch_queue_t queue =  dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);
     NSLog(@"执行操作0----------");
    dispatch_async(queue, ^{
        //执行的顺讯
        dispatch_wait(semaphore, DISPATCH_TIME_FOREVER);
        NSLog(@"开始发送请求A-----");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW,
                                     (int64_t)(4 * NSEC_PER_SEC)),
                       dispatch_get_main_queue(), ^{
                           NSLog(@"请求A数据收集-----");
                           dispatch_semaphore_signal(semaphore);
                           NSLog(@"根据数据绘制-A-的UI");
        });
    });
dispatch_async(queue, ^{
        dispatch_wait(semaphore, DISPATCH_TIME_FOREVER);
        NSLog(@"开始发送请求B-----");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW,
                                     (int64_t)(4 * NSEC_PER_SEC)),
                       dispatch_get_main_queue(), ^{
                           NSLog(@"请求B数据收集-----");
                           dispatch_semaphore_signal(semaphore);
                           NSLog(@"根据数据绘制-B-的UI");
                       });
    });
dispatch_async(queue, ^{
        dispatch_wait(semaphore, DISPATCH_TIME_FOREVER);
        NSLog(@"开始发送请求C-----");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW,
                                     (int64_t)(4 * NSEC_PER_SEC)),
                       dispatch_get_main_queue(), ^{
                           NSLog(@"请求C数据收集-----");
                           dispatch_semaphore_signal(semaphore);
                           NSLog(@"根据数据绘制-C-的UI");
                       });
    });
    NSLog(@"开始绘制UI");
    最终生成的结果：0 -> 主线程UI绘制 -> 请求 A -> A 数据 -> A UI -> 请求 B -> B 数据 -> B UI -> 请求 C -> C 数据 -> C UI
```

### pthread_mutex

互斥量表现互斥线上的数据结构，也被当做二元信号灯。常用作保护从中断来的临界段代码并且在共享同步使用的资源。

mutex(互斥量) 本质说就是一把锁，提供对资源的独占访问，所以Mutex主要的作用是用户互斥。 Mutex对象值，只有0和1两个值，这两个值分别代表了Mutex的两种状态，值是0，表示锁定的状态，当前对象被锁定，用户进程/线程如果试图lock临界资源，则进入排队等待；值为1，表示空闲状态，当前对象为空闲，用户进程/线程可以lock临界资源，之后Mutex值减1变为0.

mutex的几个操作，主要集中在
创建： pthread_mutex_init,创建有初始值，锁定状态处于空闲状态
加锁： pthread_mutex_lock
解锁： pthread_mutex_unlock
销毁： pthread_mutex_destory


##### 信号量和互斥量之前的区别：

信号量用于多线程任务同步的，一个线程完成了某一个动作就通过信号量告诉别的线层，别的线程再进行某些动作（大家都在semtake的时候，就阻塞在哪里了）；
互斥锁是用在多线程多任务互斥的，一个线程占用了某一个线程资源，那么别的线程就无法访问，直到这个线程unlock，其他的线程才开始可以利用资源。

信号量不一定是锁定某一个资源，而是流程上的概念，比如：有A,B两个线程，B线程要等A线程完成某一任务以后再进行自己下面的步骤，这个任务 并不一定是锁定某一资源，还可以是进行一些计算或者数据处理之类。
线程互斥量则是“锁住某一资源”的概念，在锁定期间内，其他线程无法对被保护的数据进 行操作。在有些情况下两者可以互换。

``` xml
 dispatch_queue_t queue =  dispatch_get_global_queue(QOS_CLASS_DEFAULT, 0);
    __block pthread_mutex_t mutex;
    //进行初始化操作，
    pthread_mutex_init(&mutex,NULL);
    dispatch_async(queue, ^{
        pthread_mutex_lock(&mutex);
        NSLog(@"发送请求A---");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            NSLog(@"处理数据A---");
            pthread_mutex_unlock(&mutex);
            NSLog(@"绘制数据A对应的UI---");
        });
    });
    dispatch_async(queue, ^{
        pthread_mutex_lock(&mutex);
        NSLog(@"发送请求B---");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            NSLog(@"处理数据B---");
            pthread_mutex_unlock(&mutex);
            NSLog(@"绘制数据B对应的UI---");
        });
    });
    dispatch_async(queue, ^{
        pthread_mutex_lock(&mutex);
        NSLog(@"发送请求C---");
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            NSLog(@"处理数据C---");
            pthread_mutex_unlock(&mutex);
            NSLog(@"绘制数据C对应的UI---");
        });
    });
```

### NSLock

NSLock 在程序中实现一个简单的互斥锁，实现了NSLockingProtocol的协议。
lock进行加锁，unlock进行解锁，trylock尝试加锁，如果失败了，并不会阻塞线程，只是立即返回。
使用tryLock并不能成功加锁，如果获取锁失败就不会执行加锁代码了。
``` xml
	NSLock *lock = [[NSLock alloc] init];
    dispatch_queue_t queue = dispatch_get_global_queue(QOS_CLASS_USER_INTERACTIVE, 0);
    dispatch_async(queue, ^{
        NSLog(@"执行A begin-----");
        [lock lock];
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            NSLog(@"执行A操作-------");
            [lock unlock];
        });
    });
    dispatch_async(queue, ^{
        NSLog(@"执行B begin-----");
        [lock lock];
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            NSLog(@"执行B操作-------");
            [lock unlock];
        });
    });
    执行的顺序是不确定的。
```

### NSCondition

条件锁：NSCondition，同样实现了NSLocking的协议

``` xml

NSCondition *cLock = [NSCondition new];

常见的API
wait: 进入等待状态
waitUntilDate：让一个线程等待一定的时间
signal: 唤醒一个等待的线程
broadcast: 唤醒所有等待的线程
//线程1
dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
    NSLog(@"start");
    [cLock lock];
    [cLock waitUntilDate:[NSDate dateWithTimeIntervalSinceNow:2]];
    NSLog(@"线程1");
    [cLock unlock];
});


//唤醒某个等待的线程
dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
    [cLock lock];
    NSLog(@"线程2加锁成功");
    [cLock wait];
    NSLog(@"线程2");
    [cLock unlock];
});

dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
    sleep(2);
    NSLog(@"唤醒一个等待的线程");
    [cLock signal];
});


//唤醒所有等待的线程
dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
    sleep(2);
    NSLog(@"唤醒所有等待的线程");
    [cLock broadcast];
});

```

### pthread_mutex(recursive)

``` xml
/递归锁
    static pthread_mutex_t pLock;
    /*
    pthread_mutexattr_t attr;
    pthread_mutexattr_init(&attr); //初始化attr并且给它赋予默认
    //设置锁类型，这边是设置为递归锁,普通的锁，递归锁
    pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_RECURSIVE);
    pthread_mutex_init(&pLock, &attr);
    pthread_mutexattr_destroy(&attr); //销毁一个属性对象，在重新进行初始化之前该结构不能重新使用
     */
    //线程1
    dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{
        static void (^RecursiveBlock)(int);
        RecursiveBlock = ^(int value) {
            pthread_mutex_lock(&pLock);
            if (value > 0) {
                NSLog(@"value: %d", value);
                RecursiveBlock(value - 1);
            }
            pthread_mutex_unlock(&pLock);
        };
        RecursiveBlock(5);
    });
```

### NSRecursiveLock

NSRecursiveLock类定义的锁可以在同一线程多次lock，而不会造成死锁。递归锁会跟踪它被多少次lock。每次成功的lock都必须平衡调用unlock操作。只有所有的锁住和解锁操作都平衡的时候，锁才真正被释放给其他线程获得.可以得出结论： 加锁后，只能有一个线程进行访问该对象，后面的线程需需要进行排队，并且lock和unlock是对应出现的，同一个线程多次lock是不被允许的，而递归锁允许同一个线程在未释放锁时反复对该锁进行加锁操作。

### NSConditionLock

``` xml
//主线程中
    NSConditionLock *theLock = [[NSConditionLock alloc] init];
    dispatch_async(self.concurrentQueue, ^{
        for (int i=0;i<=3;i++) {
            [theLock lock];
            NSLog(@"thread1:%d",i);
            sleep(1);
            [theLock unlockWithCondition:i];
        }
    });
    dispatch_async(self.concurrentQueue, ^{
        [theLock lockWhenCondition:2];
        NSLog(@"thread2");
        [theLock unlock];
    });
输出的结果： thread1:0 -> thread1:1  -> thread1:2 -> thread2 -> thread1:3
```
NSConditionLock也跟其它的锁一样，是需要lock与unlock对应的，只是lock,lockWhenCondition:与unlock，unlockWithCondition:是可以随意组合的，当然这是与你的需求相关的。

### Synchronized

synchronized最基础的同步锁，关键字加锁，互斥锁，性能较差，不推荐使用。
1.加锁的代码量尽量少，
2.添加的OC对象必须在多个线程中都是同一对象
3.优点是不需要显示的创建锁对象，便可以实现锁的机制
4.这个同步锁，会隐式的添加一个异常处理历程来保护代码，该处理例程会在异常抛出的时候自动的释放互斥锁。

我们之前用到了做多加锁方式是： @synchronized代码块。直接进行整块的加锁。
